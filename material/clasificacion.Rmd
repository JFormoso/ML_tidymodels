---
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

background-image: url(img/portada.png)
background-size: cover
class: animated slideInRight fadeOutLeft, middle

```{r xaringan-extra-styles, include=FALSE}
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```


```{r include=FALSE}
library(countdown)
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#6c5396",
  secondary_color = "#534173",
  inverse_header_color = "#FFFFFF"
)
```

```{r , message=FALSE, warning=FALSE, include=FALSE} 
library(fontawesome)
library(emo)
```

```{r xaringan-logo, echo=FALSE}
xaringanExtra::use_logo("img/logo-tidymodels.png")
```


```{r xaringan-tachyons, echo=FALSE}
xaringanExtra::use_tachyons()
xaringanExtra::use_fit_screen()
```


# Modelos de Clasificación 


### 1º Congreso Latinoamericano de Mujeres en Bioinformática y Ciencia de Datos

---

## Vamos a modelar las especies `r emo::ji("penguin")`

### Ingreso los datos 
```{r message=FALSE, warning=FALSE}
library(tidymodels) 
library(palmerpenguins)

penguins <- palmerpenguins::penguins %>%
  drop_na() %>% #elimino valores perdidos
  select(-year,-sex, -island) #elimino columnas q no son numéricas
glimpse(penguins)
```



---

## Vamos a dividir el set de datos 

```{r split, cache=TRUE}
library(rsample)
p_split <- penguins %>%
  `initial_split`(prop=0.75)

p_train <- training(p_split)
p_test  <- testing(p_split)
p_split

# para hacer validación cruzada
p_folds <- `vfold_cv`(p_train, strata = species)
```


Estos son los datos de entrenamiento/prueba/total 

* __Vamos a _entrenar_ con 250 muestras__
* __Vamos a _validar_ con 83 muestras__
* __Datos totales: 333__


---
background-image: url(img/dt-fondo.png)
background-size: cover

## Árboles de decisión `r emo::ji("deciduous_tree")`

__Vamos a utilizar el modelo por defecto__

```{r trees,  cache=TRUE}
#especifico el modelo 
set.seed(123)
vanilla_tree_spec <-
  decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
```




---

background-image: url(img/dt-fondo.png)
background-size: cover

### Ajuste de la función de training

```{r trees2,  cache=TRUE}
#modelo vanilla sin tunning
set.seed(123)
vanilla_tree_spec %>% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %>% 
  collect_metrics()
```



---

background-image: url(img/dt-fondo.png)
background-size: cover

### Vamos a especificar 2 hiperparámatros 

```{r cache=TRUE}
set.seed(123)
trees_spec <- decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("classification") %>% 
  set_args(min_n = 20, cost_complexity = 0.1)

trees_spec %>%
  fit_resamples(species ~ ., 
                resamples = p_folds) %>% 
  collect_metrics()
```

---

background-image: url(img/dt-fondo.png)
background-size: cover

## Testing set  `r emo::ji("crystal_ball")`

__Esta es la etapa conocida como predicción__ 




---

background-image: url(img/dt-fondo.png)
background-size: cover


### Ejercicio 1 

.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
#### Teniendo en cuenta el código de la página 6 realice tuneo de los siguientes hiperparámetros

* min_n
* cost_complexity
]

`r countdown(minutes = 5, seconds = 00)`


---

background-image: url(img/rf-fondo.png)
background-size: cover

# Random Forest 


```{r cache=TRUE}
p_recipe <- training(p_split) %>%
  recipe(species~.) %>%
  step_corr(all_predictors()) %>%
  step_center(all_predictors(), -all_outcomes()) %>%
  step_scale(all_predictors(), -all_outcomes()) %>%
  prep()

#AGREGAR CON JUICE LOS PRETRATAMIENTOS
```

---

background-image: url(img/rf-fondo.png)
background-size: cover

```{r cache=TRUE}
rf_spec <- rand_forest() %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

set.seed(123)

rf_spec %>% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %>% 
  collect_metrics()
```



---
background-image: url(img/rf-fondo.png)
background-size: cover

### Random Forest con mtr=2  `r emo::ji("wrench")`

```{r cache=TRUE}
rf2_spec <- rf_spec %>% 
  set_args(mtry = 2)

set.seed(123)

rf2_spec %>% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %>% 
  collect_metrics()
```


---
background-image: url(img/rf-fondo.png)
background-size: cover

### Random Forest con mtry= 3  `r emo::ji("wrench")`

```{r cache=TRUE}
rf3_spec <- rf_spec %>% 
  set_args(mtry = 3)

set.seed(123)

rf3_spec %>% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %>% 
  collect_metrics()

```


---

background-image: url(img/rf-fondo.png)
background-size: cover

### Random Forest con mtry=4  `r emo::ji("wrench")`

```{r cache=TRUE}

rf4_spec <- rf_spec %>% 
  set_args(mtry = 4)

set.seed(123)

rf4_spec %>% 
  fit_resamples(species ~ ., 
                resamples = p_folds) %>% 
  collect_metrics()
```

---

background-image: url(img/rf-fondo.png)
background-size: cover

### Ejercicio 2

.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
#### Dejando fijo mtry=2, tunee el siguiente hiperparámetro

* min_n
]

`r countdown(minutes = 3, seconds = 00)`

---

# RESPUESTA

---
background-image: url(img/rf-fondo.png)
background-size: cover


### Tuneo de hiperparámetros automático `r emo::ji("wrench")`

```{r cache=TRUE}
tune_spec <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
) %>%
  set_mode("classification") %>%
  set_engine("ranger")

```

---
background-image: url(img/rf-fondo.png)
background-size: cover


## Workflows

```{r cache=TRUE}
tune_wf <- workflow() %>%
  add_recipe(p_recipe) %>%
  add_model(tune_spec)

set.seed(123)
trees_folds <- vfold_cv(p_train, strata = species)
```

---

### Paralelizamos los cálculos

```{r cache=TRUE, message=FALSE}
doParallel::registerDoParallel()

set.seed(123)
tune_res <- tune_grid(
  tune_wf,
  resamples = trees_folds,
  grid = 20
)

tune_res
```

---

background-image: url(img/rf-fondo.png)
background-size: cover

```{r echo=FALSE, cache=TRUE}
tune_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")

```




---
background-image: url(img/rf-fondo.png)
background-size: cover

## Elijo el mejor modelo `r emo::ji("trophy")`

* Con la función select_best

```{r cache=TRUE}
best_auc <- select_best(tune_res, "roc_auc")

final_rf <- finalize_model(
  tune_spec,
  best_auc
)

final_rf

```


---

background-image: url(img/rf-fondo.png)
background-size: cover

```{r cache=TRUE}
set.seed(123)
final_wf <- workflow() %>%
  add_recipe(p_recipe) %>%
  add_model(final_rf)

final_res <- final_wf %>%
  last_fit(p_split)

final_res %>%
  collect_metrics()
```


---
background-image: url(img/rf-fondo.png)
background-size: cover

### Importancia de las variables

* libreria vip

```{r message=FALSE, warning=FALSE, eval=FALSE, cache=TRUE}
library(vip)
set.seed(123)
final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(species ~ .,
      data = juice(p_recipe)) %>%
  vip(geom = "point")

```

---

background-image: url(img/rf-fondo.png)
background-size: cover

### Gráfico 
```{r message=FALSE, warning=FALSE, echo=FALSE, cache=TRUE}
library(vip)
set.seed(123)
final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(species ~ .,
      data = juice(p_recipe)) %>%
  vip(geom = "point")

```

---

background-image: url(img/rf-fondo.png)
background-size: cover

## Ejercicio 3

.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
#### Realice un gráfico de importancia de variables con el modelo de árboles de decisión

]

`r countdown(minutes = 5, seconds = 00)`