---
title: "notebook"
author: "Ana Diedrichs"
date: "8/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ejemplo de K-means tomado del blog de tidymodels.org

El origen del siguiente código fue extraído de este 
enlace https://blog.rstudio.com/2020/07/17/rstudio-global-call-for-talks/

## Creación dataset ejemplo

```{r }
library(tidymodels)

set.seed(27)

centers <- tibble(
  cluster = factor(1:3), 
  num_points = c(100, 150, 50),  # number points in each cluster
  x1 = c(5, 0, -3),              # x1 coordinate of cluster center
  x2 = c(-1, 1, -2)              # x2 coordinate of cluster center
)

labelled_points <- 
  centers %>%
  mutate(
    x1 = map2(num_points, x1, rnorm),
    x2 = map2(num_points, x2, rnorm)
  ) %>% 
  select(-num_points) %>% 
  unnest(cols = c(x1, x2))

ggplot(labelled_points, aes(x1, x2, color = cluster)) +
  geom_point(alpha = 0.3)
```


## Uso de kmeans()

Se usa la función kmeans ya incluida en R base.

```{r}
points <- 
  labelled_points %>% 
  select(-cluster)

kclust <- kmeans(points, centers = 3)
kclust
```

```{r}
summary(kclust)
```

Ahora a cada datapoint del cluster le agregamos la clasificacion original del dataset

Función augment.kmeans del paquete broom

```{r}
augment(kclust, points)
```

La funcion tidy nos resume las estadisticas por cluster

```{r}
tidy(kclust)
```

Y la función glance() nos regresa un resumen en una sola fila

```{r}
glance(kclust)
```

## Realizar clustering exploratorio

Lo siguiente es para visualizar como cambia la asignacion
de datapoints al cluster, a medida que el número de clusters aumenta.

Es decir, observamos como se agrupan los datapoints a medida 
que k aumenta.

```{r}
kclusts <- 
  tibble(k = 1:9) %>%
  mutate(
    kclust = map(k, ~kmeans(points, .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, points)
  )

kclusts
```


```{r}
clusters <- 
  kclusts %>%
  unnest(cols = c(tidied))

assignments <- 
  kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- 
  kclusts %>%
  unnest(cols = c(glanced))
```

Se grafican los datapoints originales con su cluster predicho / asignado

```{r}
p1 <- 
  ggplot(assignments, aes(x = x1, y = x2)) +
  geom_point(aes(color = .cluster), alpha = 0.8) + 
  facet_wrap(~ k)
p1
```


Already we get a good sense of the proper number of clusters (3), and how the k-means algorithm functions when k is too high or too low. We can then add the centers of the cluster using the data from tidy():

```{r}
p2 <- p1 + geom_point(data = clusters, size = 10, shape = "x")
p2
```


```{r}
ggplot(clusterings, aes(k, tot.withinss)) +
  geom_line() +
  geom_point()
```

# palmerpenguins

Al primer uso del dataset, debe instalarse el paquete que lo contiene.
Luego podremos cargarlo sin problemas y usarlo para nuestro análisis.

```{r}
#install.packages("palmerpenguins")
```

## Carga del dataset en memoria y breve descripción

```{r}
library(palmerpenguins)
data(package = 'palmerpenguins')
```

Observemos el tipo de sus atributos

```{r}
str(penguins)
```

Observamos que los atributos numéricos que pueden ser de interés para kmeans son:

* bill_length_mm
* bill_depth_mm
* flipper_length_mm
* body_mass_g

Son datos de pinguinos de tres especies. Observamos
que no se relevó la misma cantidad de datos
para cada especie.

```{r}
penguins %>% 
  count(species)
```

Dado que kmeans trabaja con distancias promedios, 
¿nos regresaría algo similar a lo siguiente?
¿tendria sentido el clustering?
```{r}
penguins %>% 
  group_by(species) %>% 
  summarize(across(where(is.numeric), mean, na.rm = TRUE))
```

## Preprocesamiento de datos

```{r}
dataset <- penguins %>%
          select(bill_length_mm,bill_depth_mm,body_mass_g,flipper_length_mm)
```

```{r}
summary(dataset)
```

Hay valores perdidos, procedemos a descartarlos

```{r}
dataset <- dataset %>% 
          drop_na()
```

```{r}
summary(dataset)
```


```{r}
dataset <- map_df(dataset,as.numeric)
```

```{r}
summary(dataset)
```


*TODO histograma plot a esta altura *

## Kmeans usando las 4 columnas 

```{r}
kclust <- kmeans(dataset, centers = 3)
kclust
```

```{r}
tidy(kclust)
```


Ahora escalamos el dataset original

```{r}
kclust <- kmeans(scale(dataset), centers = 3)
tidy(kclust)

```

Rebobinemos, armemos el dataset 